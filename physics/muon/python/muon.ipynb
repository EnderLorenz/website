{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell imports sift.dat, histograms, fits the data with nonlinear model and plots the data and results simply\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#import the data and scale from ns to micro seconds\n",
    "data = loadtxt('sift.dat',unpack=True, usecols=[0])/1000\n",
    "\n",
    "# if using unsifted and un-scaled data\n",
    "# data = loadtxt('unsifted.dat',unpack=True, usecols=[0])\n",
    "# data = [x for x in data if x < 39999]\n",
    "#bin the data .02/1\n",
    "binLocs = np.arange(.02,20.02,.02)\n",
    "y, bins = np.histogram(data, bins = binLocs)\n",
    "#center bin values for fit\n",
    "x = (bins[1:]+bins[:-1])/2\n",
    "#delete bad bins###########\n",
    "x2 = np.delete(x, [0,1,2,3,4,5,6,7,8])\n",
    "y2 = np.delete(y, [0,1,2,3,4,5,6,7,8])\n",
    "\n",
    "#fit function\n",
    "def func(x, c, a, b):\n",
    "    return c + a * np.exp(-x/b)\n",
    "\n",
    "popt, pcov = curve_fit(func, x2, y2)\n",
    "\n",
    "print(\"Iterated Fit:\\n\",popt,\"\\n\",pcov)\n",
    "plt.figure()\n",
    "plt.plot(x, func(x,*popt), \n",
    "         label='%1.1f+%1.1fExp[-t/%1.1f]' % (popt[0],popt[1],popt[2]), color='red')\n",
    "plt.hist(data, len(binLocs), color = \"y\", alpha= .2, ec=\"black\")\n",
    "plt.xlabel('Decay time ($\\\\mu$s)')\n",
    "plt.ylabel('counts/bin')\n",
    "plt.title('Muon Mean Lifetime')\n",
    "plt.legend(loc=0)\n",
    "plt.savefig('muonScaled.pdf')\n",
    "plt.close( 'muonScaled.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is step 13 of the project 40 sets of 50 deacys...\n",
    "#this cell prints out the mean, variance and std of the 40 \"min experiments\"\n",
    "initelement = 0\n",
    "n_sets = 40\n",
    "setsize = 50\n",
    "bins2 = 9\n",
    "data = loadtxt('sift.dat',unpack=True, usecols=[0])/1000\n",
    "b = []\n",
    "for i in range(n_sets):\n",
    "    count = 0\n",
    "    for j in range(setsize):\n",
    "        if data[j+initelement+i*setsize] < popt[2]:\n",
    "            count += 1\n",
    "    b.append(count)\n",
    "y, bins = np.histogram(b, bins = binLocs)\n",
    "\n",
    "# calculate mean\n",
    "mean = sum(b) / len(b)\n",
    "# calculate variance using a list comprehension\n",
    "var_res = sum((xi - mean) ** 2 for xi in b) / (len(b)-1)\n",
    "sdom = np.sqrt(var_res)\n",
    "print (mean , var_res, sdom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and plot normalized results simply\n",
    "label = '$P(x) = N(\\\\mu =%1.2f,  \\\\sigma$ = %1.2f)' % (mean, sdom)\n",
    "xplot = np.linspace(mean-var_res,mean+var_res,1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(b, bins=bins2, color = \"y\", alpha= .2, ec=\"black\")\n",
    "\n",
    "plt.xlabel('Decays Less Than $\\\\tau$ out of 50 for 40 experiments')\n",
    "plt.ylabel('count')\n",
    "plt.title('Binomial Distribution of Muon Data Density Plot')\n",
    "plt.savefig('muonpy3sc.pdf')\n",
    "plt.close( 'muonpy3sc.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following cells use fancy plot options that may or may not work\n",
    "#in addition to many extra tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.optimize\n",
    "from numpy import loadtxt\n",
    "import matplotlib\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import curve_fit\n",
    "matplotlib.rc('xtick', labelsize=20)     \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, func(x,*popt), \n",
    "         label='%1.3f+%1.3fExp[-t/%1.1f]' % (popt[0],popt[1],popt[2]), color='red')\n",
    "plt.hist(data, len(binLocs), color = \"y\", alpha= .2, ec=\"black\")\n",
    "plt.xlabel('Decay time ($\\\\mu$s)', fontsize=24)\n",
    "plt.ylabel('count', fontsize=24)\n",
    "plt.title('Muon Mean Lifetime', fontsize=28)\n",
    "plt.legend(loc=0,prop={'size':24})\n",
    "fig = plt.gcf()\n",
    "DPI = fig.get_dpi()\n",
    "fig.set_size_inches(1024.0/float(DPI),768.0/float(DPI))\n",
    "plt.savefig('muonPy.pdf')\n",
    "plt.close( 'muonPy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This cell imports sift.dat, histograms, fits the data with nonlinear model, weighted least squares and least squares and plots the data and results with fancy options such as font type and sizes\n",
    "#From here on out the cells depend on each other need to make sure you are imorting sift or unsifted\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.optimize\n",
    "from numpy import loadtxt\n",
    "import matplotlib\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import curve_fit\n",
    "matplotlib.rc('xtick', labelsize=20)     \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "def exponentialfit(x, y):\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0:\n",
    "            y[i] = 1\n",
    "    n = len(x)\n",
    "    sxlny = sum(x*np.log(y))\n",
    "    slny = sum(np.log(y))\n",
    "    sx2 = sum(x**2)\n",
    "    sx = sum(x)\n",
    "    return np.exp((slny*sx2 - sx*sxlny)/(n*sx2 - sx**2)),\\\n",
    "            (n*sxlny - sx*slny)/(n*sx2 - sx**2)\n",
    "\n",
    "def exponentialweightedfit(x, y):\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0:\n",
    "            y[i] = 1\n",
    "    n = len(x)\n",
    "    sxlny = sum(x*np.log(y))\n",
    "    sx2y = sum((x**2)*y)\n",
    "    sxy = sum(x*y)\n",
    "    slny = sum(np.log(y))\n",
    "    sx2 = sum(x**2)\n",
    "    sx = sum(x)\n",
    "    sy = sum(y)\n",
    "    sylny = sum(y*np.log(y))\n",
    "    sxylny = sum(x*y*np.log(y))\n",
    "    return np.exp((sx2y*sylny - sxy*sxylny)/(sy*sx2y-sxy**2)),\\\n",
    "                   (-(sxy*sylny)+sy*sxylny)/(sy*sx2y - (sxy**2));\n",
    "\n",
    "data = loadtxt('unsifted.dat',unpack=True, usecols=[0])\n",
    "data = [x for x in data if x < 39999]\n",
    "\n",
    "binsc = np.arange(20,20020,20)\n",
    "y, bins = np.histogram(data, bins = binsc)\n",
    "x = (bins[1:]+bins[:-1])/2\n",
    "x2 = np.delete(x, [0,1,2,3,4,5,6,7,8])#delete bad bins###########\n",
    "y2 = np.delete(y, [0,1,2,3,4,5,6,7,8])\n",
    "        \n",
    "#calc background\n",
    "num = 30\n",
    "cc = 0.0\n",
    "for j in range(len(y2)-num,len(y2)):\n",
    "    cc = cc + y2[j]\n",
    "cc = cc/num\n",
    "\n",
    "a = exponentialfit(x2,y2)\n",
    "b = exponentialweightedfit(x2,y2)\n",
    "\n",
    "#iterated\n",
    "def func(x, c, a, b):\n",
    "    return c + a * np.exp(-x/b)\n",
    "\n",
    "init_vals = [cc, b[0], -1/b[1]] \n",
    "popt, pcov = curve_fit(func, x2, y2, p0=init_vals)\n",
    "\n",
    "print(\"Iterated Fit:\\n\",popt,\"\\n\",pcov)\n",
    "print(\"Weighted Lsq Fit:\\n\",b[0],-1/b[1])\n",
    "print(\"Lsq Fit:\\n\",a[0],-1/a[1])\n",
    "print(\"The estimated Background\",cc)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, func(x,*popt), \n",
    "         label='Iterated fit: %1.3f+%1.3fExp[-t/%1.1f]' % (popt[0],popt[1],popt[2]), color='red')\n",
    "plt.plot(x,func(x,cc,b[0],-1/b[1]), color='blue',\n",
    "         label='Weighted least squares fit: %1.1f+%1.3fExp[-t/%1.1f]' % (cc,b[0],-1/b[1]))\n",
    "plt.plot(x,func(x,cc,a[0],-1/a[1]), color='green',\n",
    "         label='Unweighted least squares fit: %1.1f+%1.1fExp[-t/%1.1f]' % (cc,a[0],-1/a[1]))\n",
    "plt.hist(data, len(binsc), color = \"y\", alpha= .2, ec=\"black\",label='Bins (%i)' % len(binsc))\n",
    "plt.xlabel('Decay time (ns)', fontsize=24)\n",
    "plt.ylabel('counts/bin', fontsize=24)\n",
    "plt.title('Muon Mean Lifetime', fontsize=28)\n",
    "plt.legend(loc=0,prop={'size':24})\n",
    "fig = plt.gcf()\n",
    "DPI = fig.get_dpi()\n",
    "fig.set_size_inches(1024.0/float(DPI),768.0/float(DPI))\n",
    "plt.savefig('muonPy3.pdf')\n",
    "plt.close( 'muonPy3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this cell calculates and plots the residuals it takes a minute\n",
    "y3 = y2-(popt[0]+popt[1]*np.exp(-x2/popt[2]))\n",
    "y4 = y2-(cc+b[0]*np.exp(b[1]*x2))\n",
    "y5 = y2-(cc+cc+a[0]*np.exp(a[1]*x2))\n",
    "print(sum(y3),sum(y4),sum(y5))\n",
    "rsenlm = np.sqrt(sum(y3**2)/(len(y2) - 2))\n",
    "rsewlsq = np.sqrt(sum(y4**2)/(len(y2) - 2))\n",
    "rselsq = np.sqrt(sum(y5**2)/(len(y2) - 2))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "markerline2, stemlines, _ = plt.stem(x2, y5, '-', linefmt='g')\n",
    "h1 = plt.setp(markerline2, 'markerfacecolor', 'g', label='Unweighted: RSE = %f' % rselsq)\n",
    "markerline2, stemlines, _ = plt.stem(x2, y4,linefmt='--b')\n",
    "h2 = plt.setp(markerline2, 'markerfacecolor', 'b', label='Weighted: RSE = %f' % rsewlsq)\n",
    "\n",
    "markerline1, stemlines, _ = plt.stem(x2, y3, linefmt= '-.''r')\n",
    "h3 = plt.setp(markerline1, 'markerfacecolor','r', label='Iterated: RSE = %f' % rsenlm)\n",
    "h4 = plt.plot([], [], ' ', label=\"RSE = $\\\\sqrt{\\\\frac{\\\\sum^n_{i=1}(y_i-f(x_i))^2}{n-2}}$\")\n",
    "\n",
    "plt.xlabel('fit value', fontsize=24)\n",
    "plt.ylabel('Residuals', fontsize=24)\n",
    "plt.title('Muon Fit Residuals', fontsize=28)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend([handles[3],handles[2],handles[1],handles[0]], \n",
    "           [labels[3],labels[2],labels[1],labels[0]],\n",
    "           loc=0,prop={'size':24})\n",
    "fig = plt.gcf()\n",
    "DPI = fig.get_dpi()\n",
    "fig.set_size_inches(1024.0/float(DPI),768.0/float(DPI))\n",
    "plt.savefig('muonpyres.pdf')\n",
    "plt.close( 'muonpyres.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell of functions to plot histogram determine normality and distribution \n",
    "import scipy.stats as st\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import anderson\n",
    "\n",
    "def plotHistogramResid(data, bins, fitType, fileName):\n",
    "    plt.figure()\n",
    "    plt.hist(data, bins, color = \"y\", alpha= .2, ec=\"black\")\n",
    "    plt.xlabel('residual', fontsize=24)\n",
    "    plt.ylabel('counts', fontsize=24)\n",
    "    plt.title(fitType + ' Fit Residuals Bins', fontsize=28)\n",
    "    # plt.legend(loc=0,prop={'size':24})\n",
    "    fig = plt.gcf()\n",
    "    DPI = fig.get_dpi()\n",
    "    fig.set_size_inches(1024.0/float(DPI),768.0/float(DPI))\n",
    "    plt.savefig(fileName)\n",
    "    plt.close(fileName)\n",
    "\n",
    "def get_normal_tests(data):\n",
    "    # https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/\n",
    "    # normality test\n",
    "    stat, p = shapiro(data)\n",
    "    print('Shapiro Wilk test Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    # interpret\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Shapiro Wilk test: Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Shapiro Wilk test: Sample does not look Gaussian (reject H0)')\n",
    "\n",
    "    stat, p = normaltest(data)\n",
    "    print('D\\'Agostino and Pearson\\'s Test Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    # interpret\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('D\\'Agostino and Pearson\\'s: Test: Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('D\\'Agostino and Pearson\\'s: TestSample does not look Gaussian (reject H0)')\n",
    "\n",
    "    result = anderson(data)\n",
    "    print('Anderson Statistic: %.3f' % result.statistic)\n",
    "    p = 0\n",
    "    for i in range(len(result.critical_values)):\n",
    "        sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "        if result.statistic < result.critical_values[i]:\n",
    "            print('Anderson: %.3f: %.3f, data looks normal (fail to reject H0)' % (sl, cv))\n",
    "        else:\n",
    "            print('Anderson: %.3f: %.3f, data does not look normal (reject H0)' % (sl, cv))\n",
    "    \n",
    "\n",
    "def get_best_distribution(data):#https://stackoverflow.com/questions/37487830/how-to-find-probability-distribution-and-parameters-for-real-data-python-3\n",
    "    dist_names = [\"norm\", \"exponweib\", \"weibull_max\", \"weibull_min\", \"pareto\", \"genextreme\"]\n",
    "    dist_results = []\n",
    "    params = {}\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(st, dist_name)\n",
    "        param = dist.fit(data)\n",
    "\n",
    "        params[dist_name] = param\n",
    "        # Applying the Kolmogorov-Smirnov test\n",
    "        D, p = st.kstest(data, dist_name, args=param)\n",
    "        print(\"p value for \"+dist_name+\" = \"+str(p))\n",
    "        dist_results.append((dist_name, p))\n",
    "\n",
    "    # select the best fitted distribution\n",
    "    best_dist, best_p = (max(dist_results, key=lambda item: item[1]))\n",
    "    # store the name of the best fit and its p value\n",
    "\n",
    "    print(\"Best fitting distribution: \"+str(best_dist))\n",
    "    print(\"Best p value: \"+ str(best_p))\n",
    "    print(\"Parameters for the best fit: \"+ str(params[best_dist]))\n",
    "    return best_dist, best_p, params[best_dist]\n",
    "print\n",
    "def qqPlot(data, title, fileName):\n",
    "    qqplot(data, line='s')\n",
    "    pyplot.title(title)\n",
    "    plt.savefig(fileName)\n",
    "    plt.close(fileName)\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram nlm fit residuals and look at normal tests and check \"best fit\"\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import shapiro\n",
    "binNLM = 40\n",
    "yNLM, bins = np.histogram(y3, bins =binNLM)\n",
    "total = 0\n",
    "for i in yNLM:\n",
    "    total += i\n",
    "\n",
    "plotHistogramResid(y3,binNLM, \"NLM\", \"nlmFitResidHist.pdf\")\n",
    "get_normal_tests(yNLM/total)\n",
    "get_best_distribution(yNLM/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram wlsq fit residuals and look at normal tests and check \"best fit\"\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import shapiro\n",
    "binWLsq = 40\n",
    "yLsq, bins = np.histogram(y4, bins =binWLsq)\n",
    "total = 0\n",
    "for i in yNLM:\n",
    "    total += i\n",
    "\n",
    "plotHistogramResid(y4, binWLsq, \"WLSQ\", \"wlsqFitResidHist.pdf\")\n",
    "get_normal_tests(yLsq/total)\n",
    "get_best_distribution(yLsq/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram lsq fit residuals and look at normal tests and check \"best fit\"\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import shapiro\n",
    "binLsq = 40\n",
    "yLsq, bins = np.histogram(y5, bins =binLsq)\n",
    "total = 0\n",
    "for i in yNLM:\n",
    "    total += i\n",
    "\n",
    "plotHistogramResid(y5, binLsq, \"LSQ\", \"lsqFitResidHist.pdf\")\n",
    "get_normal_tests(yLsq/total)\n",
    "get_best_distribution(yLsq/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this is step 13 of the project 40 sets of 50 deacys...\n",
    "#this cell prints out the mean, variance and std of the 40 \"min experiments\"\n",
    "initelement = 0\n",
    "n_sets = 40\n",
    "setsize = 50\n",
    "bins2 = 9\n",
    "data = loadtxt('unsifted.dat',unpack=True, usecols=[0])\n",
    "data = [x for x in data if x < 39999]\n",
    "b = []\n",
    "for i in range(n_sets):\n",
    "    count = 0\n",
    "    for j in range(setsize):\n",
    "        if data[j+initelement+i*setsize] < popt[2]:\n",
    "            count += 1\n",
    "    b.append(count)\n",
    "y, bins = np.histogram(b, bins = binsc)\n",
    "\n",
    "\n",
    "# calculate mean\n",
    "mean = sum(b) / len(b)\n",
    "# calculate variance using a list comprehension\n",
    "var_res = sum((xi - mean) ** 2 for xi in b) / (len(b)-1)\n",
    "sdom = np.sqrt(var_res)\n",
    "print (mean , var_res, sdom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and plot normalized results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# label = '$P(x) = \\\\frac{1}{{\\\\sigma \\\\sqrt {2\\\\pi } }}e^{{{ - \\\\left( {x - \\\\mu } \\\\right)^2 } \\\\mathord{\\\\left/ {\\\\vphantom {{ - \\\\left( {x - \\\\mu } \\\\right)^2 } {2\\\\sigma ^2 }}} \\\\right. \\\\kern-\\\\nulldelimiterspace} {2\\\\sigma ^2 }}}$'\n",
    "label = '$N(\\\\mu =%1.1f,  \\\\sigma$ = %1.1f)' % (mean, sdom)\n",
    "\n",
    "xplot = np.linspace(mean-var_res,mean+var_res,1000)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'black'\n",
    "ax1.set_xlabel('Decays Less Than $\\\\tau$ out of 50 for 40 experiments', fontsize=24)\n",
    "ax1.set_ylabel('P(x)', color=color, fontsize=24)\n",
    "ax1.plot(xplot,(1/(sdom*np.sqrt(2.0*np.pi)))*np.exp(-(((xplot-mean)*(xplot-mean))/(2.0*var_res))), \n",
    "         color='blue',label=label)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "#ax1.legend(loc=1,prop={'size':20})\n",
    "ax1.axis(ymin=0.0,ymax=.14)\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2.set_ylabel('counts', color=color, fontsize=24)  # we already handled the x-label with ax1\n",
    "ax2.hist(b, bins=bins2,color = \"y\", alpha= .2, ec=\"black\")\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.legend(loc=1, bbox_to_anchor=(1,1), bbox_transform=ax1.transAxes, prop={'size':18})\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "ax2.axis(ymin=0.0,ymax=14)\n",
    "plt.title('Binomial Distribution of Muon Data', fontsize=28)\n",
    "fig = plt.gcf()\n",
    "DPI = fig.get_dpi()\n",
    "fig.set_size_inches(1024.0/float(DPI),768.0/float(DPI))\n",
    "plt.savefig('muonpy2.pdf')\n",
    "plt.close( 'muonpy2.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and plot normalized results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "label = '$N(\\\\mu =%1.1f,  \\\\sigma$ = %1.1f)' % (mean, sdom)\n",
    "xplot = np.linspace(mean-var_res,mean+var_res,1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xplot,(1/(sdom*np.sqrt(2.0*np.pi)))\n",
    "         *np.exp(-(((xplot-mean)*(xplot-mean))/(2.0*var_res))), \n",
    "         color='blue',label=label)\n",
    "plt.hist(b, bins=bins2,density = True, color = \"y\", alpha= .2, ec=\"black\")\n",
    "\n",
    "plt.xlabel('Decays Less Than $\\\\tau$ out of 50 for 40 experiments', fontsize=24)\n",
    "plt.ylabel('P(x)', fontsize=24)\n",
    "plt.title('Binomial Distribution of Muon Data Density Plot', fontsize=28)\n",
    "plt.legend(loc=0,prop={'size':24})\n",
    "fig = plt.gcf()\n",
    "DPI = fig.get_dpi()\n",
    "fig.set_size_inches(1024.0/float(DPI),768.0/float(DPI))\n",
    "plt.savefig('muonpy3.pdf')\n",
    "plt.close( 'muonpy3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data for normalcy \n",
    "get_normal_tests(b)\n",
    "get_best_distribution(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is that the Central Limit Theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(b)\n",
    "qqPlot(b, \"qq Plot of Binomial Data\", \"muonbinqq.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}